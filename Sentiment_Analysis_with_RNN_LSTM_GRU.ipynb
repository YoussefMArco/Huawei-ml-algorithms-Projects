{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptbYapTx8o8G"
      },
      "source": [
        "\n",
        "# Sentiment Analysis using RNN Architectures\n",
        "\n",
        "## Overview\n",
        "This notebook explores the use of Recurrent Neural Networks (RNNs) for sentiment analysis on text data. The goal is to classify text samples based on their sentiment (e.g., positive or negative) using different RNN-based architectures, namely:\n",
        "- SimpleRNN\n",
        "- Long Short-Term Memory (LSTM)\n",
        "- Gated Recurrent Units (GRU)\n",
        "\n",
        "## Objectives\n",
        "1. Demonstrate the preprocessing steps required for text-based sentiment analysis.\n",
        "2. Compare the performance of various RNN architectures on the same dataset.\n",
        "3. Discuss insights gained from the results and suggest possible improvements.\n",
        "\n",
        "## Dataset\n",
        "The dataset used for this analysis consists of labeled text samples, where each sample is associated with a sentiment class. We preprocess the dataset by tokenizing the text, converting it to sequences, and padding them for uniformity.\n",
        "\n",
        "## Why RNNs for NLP?\n",
        "Recurrent Neural Networks (RNNs) are well-suited for Natural Language Processing (NLP) tasks due to their ability to process sequential data effectively. Unlike traditional feedforward networks, RNNs can retain contextual information, making them a natural choice for text classification tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzFfZWs8o8I"
      },
      "source": [
        "\n",
        "## Theoretical Background\n",
        "\n",
        "### Recurrent Neural Networks (RNNs)\n",
        "RNNs are a type of neural network designed for sequence data. They maintain a hidden state that captures information from previous time steps, allowing them to model dependencies in sequential data.\n",
        "\n",
        "#### Limitations of RNNs\n",
        "While RNNs are powerful, they struggle with long-term dependencies due to the vanishing gradient problem. This limitation led to the development of advanced architectures like LSTM and GRU.\n",
        "\n",
        "### Long Short-Term Memory (LSTM)\n",
        "LSTMs address the vanishing gradient problem by introducing memory cells and gates (input, forget, and output gates) that regulate the flow of information. This makes LSTMs capable of learning long-term dependencies.\n",
        "\n",
        "### Gated Recurrent Units (GRU)\n",
        "GRUs are a simplified version of LSTMs with fewer parameters. They combine the forget and input gates into a single update gate, reducing computational complexity while maintaining performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F34-xNCTFNwP"
      },
      "source": [
        "Sentiment Analysis with differnt RNN types:\n",
        "https://www.geeksforgeeks.org/sentiment-analysis-with-an-recurrent-neural-networks-rnn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agPTesxwHQkn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aPL9_ldHhwe",
        "outputId": "9bcefd64-b9e5-4f2a-e68e-4a86578312f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ],
      "source": [
        "# Getting reviews with words that come under 5000\n",
        "# most occurring words in the entire\n",
        "# corpus of textual review data\n",
        "vocab_size = 5000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "print(x_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVafK8noH05_",
        "outputId": "d64927ad-f35d-49db-95da-b19a6c2ae4b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mfZZiywH9yH",
        "outputId": "df0ae487-3c9a-49ee-94c7-8f5c79a7d145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "['the', 'as', 'you', 'with', 'out', 'themselves', 'powerful', 'lets', 'loves', 'their', 'becomes', 'reaching', 'had', 'journalist', 'of', 'lot', 'from', 'anyone', 'to', 'have', 'after', 'out', 'atmosphere', 'never', 'more', 'room', 'and', 'it', 'so', 'heart', 'shows', 'to', 'years', 'of', 'every', 'never', 'going', 'and', 'help', 'moments', 'or', 'of', 'every', 'chest', 'visual', 'movie', 'except', 'her', 'was', 'several', 'of', 'enough', 'more', 'with', 'is', 'now', 'current', 'film', 'as', 'you', 'of', 'mine', 'potentially', 'unfortunately', 'of', 'you', 'than', 'him', 'that', 'with', 'out', 'themselves', 'her', 'get', 'for', 'was', 'camp', 'of', 'you', 'movie', 'sometimes', 'movie', 'that', 'with', 'scary', 'but', 'and', 'to', 'story', 'wonderful', 'that', 'in', 'seeing', 'in', 'character', 'to', 'of', '70s', 'and', 'with', 'heart', 'had', 'shadows', 'they', 'of', 'here', 'that', 'with', 'her', 'serious', 'to', 'have', 'does', 'when', 'from', 'why', 'what', 'have', 'critics', 'they', 'is', 'you', 'that', \"isn't\", 'one', 'will', 'very', 'to', 'as', 'itself', 'with', 'other', 'and', 'in', 'of', 'seen', 'over', 'and', 'for', 'anyone', 'of', 'and', 'br', \"show's\", 'to', 'whether', 'from', 'than', 'out', 'themselves', 'history', 'he', 'name', 'half', 'some', 'br', 'of', 'and', 'odd', 'was', 'two', 'most', 'of', 'mean', 'for', '1', 'any', 'an', 'boat', 'she', 'he', 'should', 'is', 'thought', 'and', 'but', 'of', 'script', 'you', 'not', 'while', 'history', 'he', 'heart', 'to', 'real', 'at', 'and', 'but', 'when', 'from', 'one', 'bit', 'then', 'have', 'two', 'of', 'script', 'their', 'with', 'her', 'nobody', 'most', 'that', 'with', \"wasn't\", 'to', 'with', 'armed', 'acting', 'watch', 'an', 'for', 'with', 'and', 'film', 'want', 'an']\n"
          ]
        }
      ],
      "source": [
        "# Getting all the words from word_index dictionary\n",
        "word_idx = imdb.get_word_index()\n",
        "\n",
        "# Originally the index number of a value and not a key,\n",
        "# hence converting the index as key and the words as values\n",
        "word_idx = {i: word for word, i in word_idx.items()}\n",
        "\n",
        "# again printing the review\n",
        "print([word_idx[i] for i in x_train[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXNe3fzHIDcv",
        "outputId": "ce47c178-97f9-4402-f8ac-91f680688795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length of a review::  2697\n",
            "Min length of a review::  70\n"
          ]
        }
      ],
      "source": [
        "# Get the minimum and the maximum length of reviews\n",
        "print(\"Max length of a review:: \", len(max((x_train+x_test), key=len)))\n",
        "print(\"Min length of a review:: \", len(min((x_train+x_test), key=len)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqH6dLx4ILeX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Keeping a fixed length of all reviews to max 400 words\n",
        "max_words = 400\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_words)\n",
        "\n",
        "x_valid, y_valid = x_train[:64], y_train[:64]\n",
        "x_train_, y_train_ = x_train[64:], y_train[64:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL0h2eB3IUfX",
        "outputId": "5a554039-26a1-40a0-e2e0-e4466209c633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   66,   52,   20],\n",
              "       [ 410,    7, 1045, ..., 3106,  101,  251],\n",
              "       [   0,    0,    0, ...,    6,  415, 2981],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCmGVNhtIXx_",
        "outputId": "01d1652f-f2c0-4c18-f4b9-af74aaabbe1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24936, 400)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kby6v5BkIhxH"
      },
      "source": [
        "1- SimpleRNN (also called Vanilla RNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB9h-Y1_Iddf",
        "outputId": "f25c1b85-02b4-4f34-9552-1786367ab5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Simple_RNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 400, 32)           160000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 128)               20608     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180737 (706.00 KB)\n",
            "Trainable params: 180737 (706.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# fixing every word's embedding size to be 32\n",
        "embd_len = 32\n",
        "\n",
        "# Creating a RNN model\n",
        "RNN_model = Sequential(name=\"Simple_RNN\")\n",
        "RNN_model.add(Embedding(vocab_size,\n",
        "                        embd_len,\n",
        "                        input_length=max_words))\n",
        "\n",
        "# In case of a stacked(more than one layer of RNN)\n",
        "# use return_sequences=True\n",
        "RNN_model.add(SimpleRNN(128,\n",
        "                        activation='tanh',\n",
        "                        return_sequences=False))\n",
        "RNN_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# printing model summary\n",
        "print(RNN_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKULQlbnI3SY",
        "outputId": "4c116c85-61e7-42b9-8959-3df77fc1165a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 43s 106ms/step - loss: 0.6909 - accuracy: 0.5243 - val_loss: 0.7139 - val_accuracy: 0.4062\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 40s 103ms/step - loss: 0.6280 - accuracy: 0.6479 - val_loss: 1.1199 - val_accuracy: 0.4375\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 40s 103ms/step - loss: 0.6438 - accuracy: 0.6288 - val_loss: 0.6489 - val_accuracy: 0.6250\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 40s 103ms/step - loss: 0.5844 - accuracy: 0.6857 - val_loss: 0.6822 - val_accuracy: 0.6406\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 41s 104ms/step - loss: 0.5310 - accuracy: 0.7230 - val_loss: 0.6444 - val_accuracy: 0.6719\n"
          ]
        }
      ],
      "source": [
        "# Compiling model\n",
        "RNN_model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "history = RNN_model.fit(x_train_, y_train_,\n",
        "                        batch_size=64,\n",
        "                        epochs=5,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxyg8InVJp4w",
        "outputId": "f9c2acc7-82ea-4b5d-de1a-20de98d196b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Simple_RNN Score--->  [0.5856955647468567, 0.684440016746521]\n"
          ]
        }
      ],
      "source": [
        "# Printing model score on test data\n",
        "print()\n",
        "print(\"Simple_RNN Score---> \", RNN_model.evaluate(x_test, y_test, verbose=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GERvTdZ8J3np"
      },
      "source": [
        "2-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZkaioyWJqrY",
        "outputId": "9011efbe-98c2-430a-ea0c-f0951c269b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"LSTM_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 400, 32)           160000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               82432     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 242561 (947.50 KB)\n",
            "Trainable params: 242561 (947.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Defining LSTM model\n",
        "lstm_model = Sequential(name=\"LSTM_Model\")\n",
        "lstm_model.add(Embedding(vocab_size,\n",
        "                         embd_len,\n",
        "                         input_length=max_words))\n",
        "lstm_model.add(LSTM(128,\n",
        "                    activation='relu',\n",
        "                    return_sequences=False))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Printing Model Summary\n",
        "print(lstm_model.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWV41OqxJ-Nf",
        "outputId": "09a4f893-fc6d-450b-e62d-13c4a1447826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 - 181s - loss: nan - accuracy: 0.5084 - val_loss: nan - val_accuracy: 0.6094 - 181s/epoch - 464ms/step\n",
            "Epoch 2/5\n",
            "390/390 - 179s - loss: nan - accuracy: 0.4997 - val_loss: nan - val_accuracy: 0.6094 - 179s/epoch - 459ms/step\n",
            "Epoch 3/5\n",
            "390/390 - 178s - loss: nan - accuracy: 0.4997 - val_loss: nan - val_accuracy: 0.6094 - 178s/epoch - 457ms/step\n",
            "Epoch 4/5\n",
            "390/390 - 177s - loss: nan - accuracy: 0.4997 - val_loss: nan - val_accuracy: 0.6094 - 177s/epoch - 455ms/step\n",
            "Epoch 5/5\n",
            "390/390 - 178s - loss: nan - accuracy: 0.4997 - val_loss: nan - val_accuracy: 0.6094 - 178s/epoch - 457ms/step\n"
          ]
        }
      ],
      "source": [
        "# Compiling the model\n",
        "lstm_model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "history3 = lstm_model.fit(x_train_, y_train_,\n",
        "                          batch_size=64,\n",
        "                          epochs=5,\n",
        "                          verbose=2,\n",
        "                          validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9rJgO5IJ-9A",
        "outputId": "d9f82dcf-7f69-48f2-ad61-a44432c4a950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "782/782 [==============================] - 86s 110ms/step - loss: nan - accuracy: 0.5000\n",
            "LSTM model Score--->  [nan, 0.5]\n"
          ]
        }
      ],
      "source": [
        "# Displaying the model accuracy on test data\n",
        "print()\n",
        "print(\"LSTM model Score---> \", lstm_model.evaluate(x_test, y_test, verbose=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvvYsQVgKCyx"
      },
      "source": [
        "3- GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix2AKYA4KFVg",
        "outputId": "5b9e2ae7-1005-465e-e0ab-acd89308b215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"GRU_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 400, 32)           160000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               62208     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 222337 (868.50 KB)\n",
            "Trainable params: 222337 (868.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Defining GRU model\n",
        "gru_model = Sequential(name=\"GRU_Model\")\n",
        "gru_model.add(Embedding(vocab_size,\n",
        "                        embd_len,\n",
        "                        input_length=max_words))\n",
        "gru_model.add(GRU(128,\n",
        "                  activation='tanh',\n",
        "                  return_sequences=False))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Printing the Summary\n",
        "print(gru_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxtaAezOKKBK",
        "outputId": "05c43bf0-1a3a-436c-f3a8-666e75dc6357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 154s 388ms/step - loss: 0.5261 - accuracy: 0.7268 - val_loss: 0.3372 - val_accuracy: 0.8906\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 151s 388ms/step - loss: 0.3885 - accuracy: 0.8382 - val_loss: 0.2207 - val_accuracy: 0.9531\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 150s 384ms/step - loss: 0.2703 - accuracy: 0.8938 - val_loss: 0.2168 - val_accuracy: 0.9062\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 150s 385ms/step - loss: 0.2270 - accuracy: 0.9123 - val_loss: 0.1859 - val_accuracy: 0.9062\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 151s 386ms/step - loss: 0.1889 - accuracy: 0.9291 - val_loss: 0.1712 - val_accuracy: 0.9219\n"
          ]
        }
      ],
      "source": [
        "# Compiling the model\n",
        "gru_model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training the GRU model\n",
        "history2 = gru_model.fit(x_train_, y_train_,\n",
        "                         batch_size=64,\n",
        "                         epochs=5,\n",
        "                         verbose=1,\n",
        "                         validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTMNA8uKKNXI",
        "outputId": "f69c7e54-80f3-4bc8-879c-bd8f3d2c1863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "782/782 [==============================] - 41s 51ms/step - loss: 0.3080 - accuracy: 0.8812\n",
            "GRU model Score--->  [0.30800050497055054, 0.8811600208282471]\n"
          ]
        }
      ],
      "source": [
        "# Printing model score on test data\n",
        "print()\n",
        "print(\"GRU model Score---> \", gru_model.evaluate(x_test, y_test, verbose=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXvA8i3xKaun"
      },
      "source": [
        "4- Bi-directional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U0CDc3CKdBX",
        "outputId": "6af9834d-c8aa-4a6d-b0ce-34f93afdfc93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Bidirectional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 400, 32)           160000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256)               164864    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 325121 (1.24 MB)\n",
            "Trainable params: 325121 (1.24 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Defining Bidirectional LSTM model\n",
        "bi_lstm_model = Sequential(name=\"Bidirectional_LSTM\")\n",
        "bi_lstm_model.add(Embedding(vocab_size,\n",
        "                            embd_len,\n",
        "                            input_length=max_words))\n",
        "bi_lstm_model.add(Bidirectional(LSTM(128,\n",
        "                                     activation='tanh',\n",
        "                                     return_sequences=False)))\n",
        "bi_lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Printing model summary\n",
        "print(bi_lstm_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVFORfuBKheQ",
        "outputId": "c2ce6d48-0fd6-4a96-c8d4-0207b602771f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 474s 1s/step - loss: 0.4911 - accuracy: 0.7540 - val_loss: 0.3578 - val_accuracy: 0.8499\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 469s 1s/step - loss: 0.3107 - accuracy: 0.8761 - val_loss: 0.3274 - val_accuracy: 0.8660\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 469s 1s/step - loss: 0.2958 - accuracy: 0.8834 - val_loss: 0.3608 - val_accuracy: 0.8474\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 469s 1s/step - loss: 0.2544 - accuracy: 0.9020 - val_loss: 0.3370 - val_accuracy: 0.8651\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 468s 1s/step - loss: 0.2369 - accuracy: 0.9078 - val_loss: 0.3508 - val_accuracy: 0.8570\n"
          ]
        }
      ],
      "source": [
        "# Compiling model summary\n",
        "bi_lstm_model.compile(\n",
        "  loss=\"binary_crossentropy\",\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training the model\n",
        "history4 = bi_lstm_model.fit(x_train_, y_train_,\n",
        "                             batch_size=64,\n",
        "                             epochs=5,\n",
        "                             verbose=1,\n",
        "                             validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1wTqXIHGKo94",
        "outputId": "1b4ea3b0-ff45-43db-c3f7-6043c32f6fac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bidirectional LSTM model Score--->  [0.35081273317337036, 0.8570399880409241]\n"
          ]
        }
      ],
      "source": [
        "# Printing model score on test data\n",
        "print()\n",
        "print(\"Bidirectional LSTM model Score---> \",\n",
        "      bi_lstm_model.evaluate(x_test, y_test, verbose=0))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}